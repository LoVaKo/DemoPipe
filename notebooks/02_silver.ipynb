{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24d9d1a4",
   "metadata": {},
   "source": [
    "# Silver Layer - Clean and Structure the Data\n",
    "\n",
    "ðŸŽ¯ **Goal**: Make the data clean, consistent, and usable for downstream tasks\n",
    "\n",
    "ðŸ”§ **Tasks a data engineer performs**:\n",
    "- Read from the bronze layer\n",
    "- Flatten nested structures (e.g. explode arrays)\n",
    "- Drop invalid or duplicate rows\n",
    "- Convert data types to the correct formats (e.g., height as float)\n",
    "- Rename columns for clarity or consistency\n",
    "- Store result as a new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17faad43",
   "metadata": {},
   "source": [
    "### ðŸ§¹ This notebook: Silver Layer â€“ Cleaned & Structured PokÃ©mon Data\n",
    "\n",
    "In this notebook, we:\n",
    "- Read the raw PokÃ©mon data from the bronze Delta table\n",
    "- Extract selected fields from the nested `raw_json` column\n",
    "- Explode arrays such as `types` into individual rows\n",
    "- Ensure data types are consistent (e.g. height as float)\n",
    "- Rename or restructure columns for clarity\n",
    "- Save the cleaned data to a new Delta table in the silver layer at `../data/silver/pokemon`\n",
    "\n",
    "This layer prepares the data for analysis and ML by enforcing structure and consistency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46134ac0",
   "metadata": {},
   "source": [
    "# Step 1: Import Spark and setup the session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, from_json\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DemoPipe - Silver Layer\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.3.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Confirm Spark is running\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196fe02",
   "metadata": {},
   "source": [
    "# Step 2: Define paths to bronze and silver tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480069b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_path = \"../data/bronze/pokemon\"\n",
    "silver_path = \"../data/silver/pokemon\"\n",
    "\n",
    "# For Databricks:\n",
    "# bronze_path = \"dbfs:/tmp/bronze/pokemon\"\n",
    "# silver_path = \"dbfs:/tmp/silver/pokemon\"\n",
    "\n",
    "# For Microsoft Fabric:\n",
    "# bronze_path = \"Tables/bronze_pokemon\"\n",
    "# silver_path = \"Tables/silver_pokemon\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d187be3",
   "metadata": {},
   "source": [
    "# Step 3: Load the raw bronze Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44aba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_df = spark.read.format(\"delta\").load(bronze_path)\n",
    "bronze_df.printSchema()\n",
    "bronze_df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8da38b",
   "metadata": {},
   "source": [
    "# Step 4: Define schema to parse JSON string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_schema = StructType([\n",
    "    StructField(\"height\", IntegerType(), True),\n",
    "    StructField(\"weight\", IntegerType(), True),\n",
    "    StructField(\"base_experience\", IntegerType(), True),\n",
    "    StructField(\"types\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"slot\", IntegerType(), True),\n",
    "            StructField(\"type\", StructType([\n",
    "                StructField(\"name\", StringType(), True),\n",
    "                StructField(\"url\", StringType(), True)\n",
    "            ]), True)\n",
    "        ])\n",
    "    ), True),\n",
    "    StructField(\"stats\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"base_stat\", IntegerType(), True),\n",
    "            StructField(\"effort\", IntegerType(), True),\n",
    "            StructField(\"stat\", StructType([\n",
    "                StructField(\"name\", StringType(), True),\n",
    "                StructField(\"url\", StringType(), True)\n",
    "            ]), True)\n",
    "        ])\n",
    "    ), True),\n",
    "    StructField(\"abilities\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"is_hidden\", BooleanType(), True),\n",
    "            StructField(\"slot\", IntegerType(), True),\n",
    "            StructField(\"ability\", StructType([\n",
    "                StructField(\"name\", StringType(), True),\n",
    "                StructField(\"url\", StringType(), True)\n",
    "            ]), True)\n",
    "        ])\n",
    "    ), True),\n",
    "    StructField(\"moves\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"move\", StructType([\n",
    "                StructField(\"name\", StringType(), True),\n",
    "                StructField(\"url\", StringType(), True)\n",
    "            ]), True)\n",
    "        ])\n",
    "    ), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15049bbf",
   "metadata": {},
   "source": [
    "# Step 5: Parse raw JSON string to struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed = bronze_df.withColumn(\"parsed\", from_json(col(\"raw_json\"), parsed_schema))\n",
    "df_parsed.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17517f",
   "metadata": {},
   "source": [
    "# Step 6: Extract fields from struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = df_parsed.select(\n",
    "    col(\"id\"),\n",
    "    col(\"name\"),\n",
    "    col(\"parsed.height\").alias(\"height\"),\n",
    "    col(\"parsed.weight\").alias(\"weight\"),\n",
    "    col(\"parsed.base_experience\").alias(\"base_experience\")\n",
    ")\n",
    "\n",
    "types_df = df_parsed.select(\"id\", \"name\", explode(\"parsed.types\").alias(\"type\")) \\\n",
    "    .select(\"id\", \"name\", col(\"type.type.name\").alias(\"type_name\"))\n",
    "\n",
    "abilities_df = df_parsed.select(\"id\", \"name\", explode(\"parsed.abilities\").alias(\"ability\")) \\\n",
    "    .select(\"id\", \"name\", col(\"ability.ability.name\").alias(\"ability_name\"), col(\"ability.is_hidden\"))\n",
    "\n",
    "stats_df = df_parsed.select(\"id\", \"name\", explode(\"parsed.stats\").alias(\"stat\")) \\\n",
    "    .select(\"id\", \"name\", col(\"stat.stat.name\").alias(\"stat_name\"), col(\"stat.base_stat\").alias(\"stat_value\"))\n",
    "\n",
    "moves_df = df_parsed.select(\"id\", \"name\", explode(\"parsed.moves\").alias(\"move\")) \\\n",
    "    .select(\"id\", \"name\", col(\"move.move.name\").alias(\"move_name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c519829",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.printSchema()\n",
    "types_df.printSchema()\n",
    "abilities_df.printSchema()\n",
    "stats_df.printSchema()\n",
    "moves_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df2743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4d6e0",
   "metadata": {},
   "source": [
    "# Step 7: Save exploded tables seperately for accurate multi-valued representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f337da",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{silver_path}/base\")\n",
    "types_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{silver_path}/types\")\n",
    "abilities_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{silver_path}/abilities\")\n",
    "stats_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{silver_path}/stats\")\n",
    "moves_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{silver_path}/moves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e552f5b",
   "metadata": {},
   "source": [
    "# Optional: Read and verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eaed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"delta\").load(f\"{silver_path}/base\").show(5)\n",
    "spark.read.format(\"delta\").load(f\"{silver_path}/types\").show(5)\n",
    "spark.read.format(\"delta\").load(f\"{silver_path}/abilities\").show(5)\n",
    "spark.read.format(\"delta\").load(f\"{silver_path}/stats\").show(5)\n",
    "spark.read.format(\"delta\").load(f\"{silver_path}/moves\").show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
